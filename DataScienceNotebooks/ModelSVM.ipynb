{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from sklearn import svm\n",
    "import pandas.io.sql as psql\n",
    "import psycopg2\n",
    "import re\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import grid_search\n",
    "import xgboost as xgb\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Database connection details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/Users/krishna/MOOC/smart-city/login.json') as data_file:\n",
    "    db = json.load(data_file)\n",
    "\n",
    "conn = psycopg2.connect(database=db['dbname'], user=db['user'], password=db['password'], host=db['host'], port=db['port'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/pandas/io/sql.py:1569: FutureWarning: frame_query is deprecated, use read_sql\n",
      "  warnings.warn(\"frame_query is deprecated, use read_sql\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "dataframe = psql.frame_query(\"select idd, text, 2*alch_score +3 as alch_score_norm, local_score from twitter.tweets where (2*alch_score+3) - local_score < 1 and (2*alch_score+3 - local_score) > - 1 and alch_score != '0'  ;\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idd</th>\n",
       "      <th>text</th>\n",
       "      <th>alch_score_norm</th>\n",
       "      <th>local_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 713126956317990916</td>\n",
       "      <td> RT @SireCedric: Quais du Polar (Lyon) mes hora...</td>\n",
       "      <td> 1.554584</td>\n",
       "      <td> 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 715372139143172096</td>\n",
       "      <td> RT @OLAngElles: Suite à sa victoire face à bar...</td>\n",
       "      <td> 3.642358</td>\n",
       "      <td> 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 715377326188535808</td>\n",
       "      <td> RT @RicoMdt185: Les keuf ont la haine comme Ly...</td>\n",
       "      <td> 1.554582</td>\n",
       "      <td> 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 715374761778487297</td>\n",
       "      <td> #Depuis que Lyon s’est éveillé à la Chine en 2...</td>\n",
       "      <td> 1.554582</td>\n",
       "      <td> 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 715389838883561472</td>\n",
       "      <td>                                     Jamal Lyon ❤️</td>\n",
       "      <td> 3.588044</td>\n",
       "      <td> 3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  idd                                               text  \\\n",
       "0  713126956317990916  RT @SireCedric: Quais du Polar (Lyon) mes hora...   \n",
       "1  715372139143172096  RT @OLAngElles: Suite à sa victoire face à bar...   \n",
       "2  715377326188535808  RT @RicoMdt185: Les keuf ont la haine comme Ly...   \n",
       "3  715374761778487297  #Depuis que Lyon s’est éveillé à la Chine en 2...   \n",
       "4  715389838883561472                                      Jamal Lyon ❤️   \n",
       "\n",
       "   alch_score_norm  local_score  \n",
       "0         1.554584            2  \n",
       "1         3.642358            3  \n",
       "2         1.554582            2  \n",
       "3         1.554582            2  \n",
       "4         3.588044            3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1437, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processTweet(tweet):\n",
    "    #Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    #Convert www.* or https?://* to URL\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',tweet)\n",
    "    #Convert @username to AT_USER\n",
    "    tweet = re.sub('@[^\\s]+',' ',tweet)\n",
    "    #Remove additional white spaces\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "    #Replace #word with word\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "    #trim\n",
    "    tweet = tweet.strip('\\'\"')\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe['text']= dataframe['text'].apply(lambda x : processTweet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe['avg'] = dataframe.apply(lambda x : round((x['alch_score_norm'] + x['local_score'])/2) ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(dataframe, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data 1149\n",
      "Size of test data 288\n"
     ]
    }
   ],
   "source": [
    "print \"Size of training data\", len(train_data)\n",
    "print \"Size of test data\",len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=5,\n",
    "                             max_df = 1.0,\n",
    "                             sublinear_tf=True,\n",
    "                             use_idf=True)\n",
    "train_vectors = vectorizer.fit_transform(train_data['text'])\n",
    "test_vectors = vectorizer.transform(test_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1149x464 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 12098 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[.1, 10]}\n",
    "svr = svm.SVC()\n",
    "clf = grid_search.GridSearchCV(svr, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'kernel': ('linear', 'rbf'), 'C': [0.1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_vectors, train_data['avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ModelObjects/modelsvm2804.pkl',\n",
       " 'ModelObjects/modelsvm2804.pkl_01.npy',\n",
       " 'ModelObjects/modelsvm2804.pkl_02.npy',\n",
       " 'ModelObjects/modelsvm2804.pkl_03.npy',\n",
       " 'ModelObjects/modelsvm2804.pkl_04.npy',\n",
       " 'ModelObjects/modelsvm2804.pkl_05.npy',\n",
       " 'ModelObjects/modelsvm2804.pkl_06.npy',\n",
       " 'ModelObjects/modelsvm2804.pkl_07.npy',\n",
       " 'ModelObjects/modelsvm2804.pkl_08.npy',\n",
       " 'ModelObjects/modelsvm2804.pkl_09.npy',\n",
       " 'ModelObjects/modelsvm2804.pkl_10.npy',\n",
       " 'ModelObjects/modelsvm2804.pkl_11.npy',\n",
       " 'ModelObjects/modelsvm2804.pkl_12.npy',\n",
       " 'ModelObjects/modelsvm2804.pkl_13.npy',\n",
       " 'ModelObjects/modelsvm2804.pkl_14.npy',\n",
       " 'ModelObjects/modelsvm2804.pkl_15.npy',\n",
       " 'ModelObjects/modelsvm2804.pkl_16.npy',\n",
       " 'ModelObjects/modelsvm2804.pkl_17.npy',\n",
       " 'ModelObjects/modelsvm2804.pkl_18.npy']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, \"ModelObjects/modelsvm2804.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf.pkl', 'tfidf.pkl_01.npy', 'tfidf.pkl_02.npy']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(vectorizer, \"tfidf.pkl\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm_train = (train_data['local_score'],clf.predict(train_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9688752630943922"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(train_data['local_score'], clf.predict(train_vectors), average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict = clf.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  5  0  0  0]\n",
      " [ 3 94 15 10  1]\n",
      " [ 0  8 35  7  0]\n",
      " [ 0 18  7 77  2]\n",
      " [ 0  0  0  2  1]]\n"
     ]
    }
   ],
   "source": [
    "cm  = (confusion_matrix(test_data['avg'], predict))\n",
    "print cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5793111675782765"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test_data['avg'], clf.predict(test_vectors), average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly Classified 210\n",
      "Total data point  288\n"
     ]
    }
   ],
   "source": [
    "print \"Correctly Classified\",cm.trace()\n",
    "print \"Total data point \",cm.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
